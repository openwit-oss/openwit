use std::sync::Arc;
use anyhow::Result;
use tokio::sync::mpsc::{Receiver, Sender};
use tracing::{info, warn, error};

use openwit_config::UnifiedConfig;
use openwit_ingestion::{KafkaIngestor, KafkaMessage, MessagePayload};
use crate::kafka_messages::KafkaTraceMessage;

/// Adapter that converts KafkaMessage to KafkaTraceMessage for backward compatibility
async fn kafka_message_adapter(
    mut rx: Receiver<KafkaMessage>,
    tx: Sender<KafkaTraceMessage>,
) {
    while let Some(msg) = rx.recv().await {
        // Only process trace messages for now (maintaining backward compatibility)
        if let MessagePayload::Trace(export_req) = msg.payload {
            let trace_msg = KafkaTraceMessage {
                topic: msg.topic,
                key: msg.key,
                export_req,
            };
            
            if let Err(e) = tx.send(trace_msg).await {
                error!("Failed to send trace message: {:?}", e);
            }
        } else {
            // Log other message types for visibility
            match &msg.payload {
                MessagePayload::Logs(_) => {
                    info!("Received logs message from topic: {}, partition: {}", msg.topic, msg.partition);
                }
                MessagePayload::Metrics(_) => {
                    info!("Received metrics message from topic: {}, partition: {}", msg.topic, msg.partition);
                }
                MessagePayload::Raw(_) => {
                    warn!("Received raw message that couldn't be decoded from topic: {}", msg.topic);
                }
                _ => {}
            }
        }
    }
}

/// Spawns Kafka ingestors using the new decoupled ingestion module
pub async fn spawn_kafka_ingestors(
    config: Arc<UnifiedConfig>,
    tx: Sender<KafkaTraceMessage>,
) -> Result<()> {
    let kafka_cfg = if config.ingestion.kafka.brokers.is_some() {
        Arc::new(config.ingestion.kafka.clone())
    } else {
        warn!("‚ö†Ô∏è No Kafka config found. Skipping Kafka ingestors.");
        return Ok(());
    };

    info!("üöÄ Starting Kafka ingestion with pool size: {}", kafka_cfg.pool_size);

    // Create the new Kafka ingestor
    let ingestor = KafkaIngestor::new(kafka_cfg);
    
    // Start the ingestor and get the receiver
    let rx = ingestor.start().await?;
    
    // Spawn the adapter task
    tokio::spawn(kafka_message_adapter(rx, tx));
    
    // Store the ingestor handle for later use (e.g., for graceful shutdown)
    // You might want to return this or store it somewhere accessible
    tokio::spawn(async move {
        // Keep the ingestor alive
        loop {
            tokio::time::sleep(tokio::time::Duration::from_secs(60)).await;
            
            // Health check
            if !ingestor.health_check().await {
                error!("‚ùå Kafka ingestor health check failed!");
            }
            
            // Log metrics periodically
            let metrics = ingestor.get_metrics().await;
            for (i, metric) in metrics.iter().enumerate() {
                info!(
                    "üìä Consumer {} - Messages: {}, Failed: {}, Bytes: {}",
                    i,
                    metric.messages_received.load(std::sync::atomic::Ordering::Relaxed),
                    metric.messages_failed.load(std::sync::atomic::Ordering::Relaxed),
                    metric.bytes_received.load(std::sync::atomic::Ordering::Relaxed)
                );
            }
        }
    });

    Ok(())
}